{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"INFO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yd9i2JSNiw67"
   },
   "source": [
    "# Pre-processando a Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Primeiro passo é analisar os dados para entender o que será estudado\n",
    "Antes de mais nada podemos usar o comando cat para ler as linhas inicias do arquivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls -h /user/jonatas/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -cat '/user/jonatas/data/MICRODADOS_ENEM_2021.csv' | head -3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada a quantidade elevada de campos do conjunto de dados, foi optado por ser feita a inferência do esquema automaticamente para agilizar análise dos dados em detrimento da otimização do espaço usado na memória. ponto de melhoria  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_enem = spark.read.csv(\"hdfs:///user/jonatas/data/MICRODADOS_ENEM_2021.csv\"\n",
    "                               ,sep=\";\"\n",
    "                               ,inferSchema=\"True\"\n",
    "                               ,header=\"True\"\n",
    "                               ,encoding=\"latin1\"\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvamos os dados em formato parquet para otimizar espaço e agilizar a leitura dos dados brutos caso seja nessessário futuramente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!hdfs dfs -rm -r /user/jonatas/data/MICRODADOS_ENEM_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_enem.write.parquet(\"hdfs:///user/jonatas/data/MICRODADOS_ENEM_2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -ls -h /user/jonatas/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -du -s -h hdfs:///user/jonatas/data/MICRODADOS_ENEM_2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_enem = spark.read.parquet(\"hdfs:///user/jonatas/data/MICRODADOS_ENEM_2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dados_enem.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dados_enem.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dados_enem.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com auxílio do arquivo de dicionário e a análise do schema do dataframe foi possível identificar os campos e a sua relevância para a análise que pretendemos fazer. Realizando assim uma primeira filtragem dos dados,  foram removidos os campos que não são interessantes para a análise. Como a cor do caderno das provas realizadas, e o vetor das respostas e gabarito. Como dada a anatureza dos dados, o foco na análise se dará no perfil social, racial, econômico, regional e nota dos participantes, informações como qual cor de caderno eles receberam, ou quais resposta marcaram é irelevante para o estudo. O número de inscrição também não tem valor explicativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado = df_dados_enem.drop(\n",
    "    'NU_INSCRICAO',\n",
    "    'CO_PROVA_CN',\n",
    "    'CO_PROVA_CH', \n",
    "    'CO_PROVA_LC', \n",
    "    'CO_PROVA_MT',\n",
    "    'TX_RESPOSTAS_CN',\n",
    "    'TX_RESPOSTAS_CH',\n",
    "    'TX_RESPOSTAS_LC',\n",
    "    'TX_RESPOSTAS_MT',\n",
    "    'TX_GABARITO_CN',\n",
    "    'TX_GABARITO_CH',\n",
    "    'TX_GABARITO_LC',\n",
    "    'TX_GABARITO_MT'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tratado.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r /user/jonatas/data/df_tratado_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvamos o dataframe com o primeiro tratamento com o índice 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado.write.parquet(\"hdfs:///user/jonatas/data/df_tratado_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -du -s -h /user/jonatas/data/df_tratado_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise do Conjunto de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmento foi optado por fazer uma análise voltada para Feature Selection para identificar quais variávies mais explicam a nota final do ENEM, visando o desenvolvimento de um modelo de regressão para prever essa nota final.\n",
    "\n",
    "Sendo a nota final do ENEM definida como a média das 5 provas, as 4 objetivas e redação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the largest variance criteria would be akin to feature extraction,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado = spark.read.parquet(\"hdfs:///user/jonatas/data/df_tratado_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_tratado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise das variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um ponto a se destacar é que praticamente todas as nossas variáveis são qualitativas, e quando for feita a mádia das notas para compor a Nota Final que será o Target da análise, todas as variáveis restantes serão qualitativas. Para se criar um modelo de previsão em cima disso se torna necessário convertelas em variáveis dummy e isso acaretará problemas para a nossa base no estado atual que ela se encontra como veremos adiante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O principal problema se mantém sendo o tamanho da base de dados e a quantidade de colunas, o que frustrou tentativas anteriores de uma manipulação como dataframe do pandas, sendo assim necessário uma análise mais minunciosa da base e tratamento como dataframe do spark para a remoção de informação desnecessária."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como sabemos que estamos analisando os dados do enem 2021, sendo assim não precisamos da coluna de ano. \n",
    "\n",
    "Como Além do Distrito Federal e do distrito insular de Fernando de Noronha, o Brasil tem 5.568 municípios, foi optado fazer a análise somente a nível estadual pois dado que todas nossas variáveis são qualitativas e assim  atarpalharia o modelo de dummies, removendo assim as colunas de código do município e nome do município. \n",
    "\n",
    "Mantendo somente codigo da UF da escola onde foi cursado o EM e a da realização da prova. \n",
    "\n",
    "As colunas de presença nas provas objetivas e status da redação não são necessárias pois só serão considerados os participantes presentes em todas as provas e que tenham feito pontos, a remoção dos que não se encaixam nessa categoria será feita com a remoção dos NaN da Coluna a ser criada NF_Enem. \n",
    "\n",
    "As notas das competências da redação também não serão avaliadas individualmente e nem o tipo de língua estrangeira selecionada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado = df_tratado.drop(\n",
    "    #'CO_PROVA_CN','CO_PROVA_CH', 'CO_PROVA_LC', 'CO_PROVA_MT',\n",
    "    #'TX_RESPOSTAS_CN','TX_RESPOSTAS_CH','TX_RESPOSTAS_LC','TX_RESPOSTAS_MT',\n",
    "    #'TX_GABARITO_CN','TX_GABARITO_CH','TX_GABARITO_LC','TX_GABARITO_MT',\n",
    "    #'NU_INSCRICAO',\n",
    "    \n",
    "    'NU_ANO',\n",
    "    'CO_MUNICIPIO_ESC','NO_MUNICIPIO_ESC','SG_UF_ESC','TP_SIT_FUNC_ESC',\n",
    "    'CO_MUNICIPIO_PROVA','NO_MUNICIPIO_PROVA', 'SG_UF_PROVA',\n",
    "    'TP_PRESENCA_CN', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC','TP_PRESENCA_MT',\n",
    "    #'NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_MT', 'NU_NOTA_REDACAO',\n",
    "    'TP_STATUS_REDACAO', 'NU_NOTA_COMP1', 'NU_NOTA_COMP2', 'NU_NOTA_COMP3', 'NU_NOTA_COMP4', 'NU_NOTA_COMP5', \n",
    "    'TP_LINGUA'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!hdfs dfs -rm -r /user/jonatas/data/df_tratado_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado.write.parquet(\"hdfs:///user/jonatas/data/df_tratado_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -du -s -h /user/jonatas/data/df_tratado_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado = spark.read.parquet(\"hdfs:///user/jonatas/data/df_tratado_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado = df_tratado.withColumn(\n",
    "    'NF_ENEM',\n",
    "    round(\n",
    "    df_tratado.NU_NOTA_CN +\n",
    "    df_tratado.NU_NOTA_CH +\n",
    "    df_tratado.NU_NOTA_LC +\n",
    "    df_tratado.NU_NOTA_MT +\n",
    "    df_tratado.NU_NOTA_REDACAO\n",
    "    ) / 5\n",
    ").drop('NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_MT', 'NU_NOTA_REDACAO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_tratado = df_tratado.na.drop(subset=['NF_ENEM'])\n",
    "df_tratado = df_tratado.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma vez que selecionamos as colunas relevantes para nossa análise, um último passo é selecionar apenas os participantes que não tem nenhuma informação faltante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -rm -r /user/jonatas/data/df_tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tratado.write.parquet(\"hdfs:///user/jonatas/data/df_tratado_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -du -s -h /user/jonatas/data/df_tratado_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conseguimos reduzir bastante o tamanho da base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise com Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hdfs:///user/jonatas/data/df_tratado_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizarmos a análise precisamos da criação de dummys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumies_list = pd.Series([\n",
    "    'TP_FAIXA_ETARIA', 'TP_SEXO', 'TP_ESTADO_CIVIL', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ANO_CONCLUIU',\n",
    "    'TP_ESCOLA', 'TP_ENSINO', 'IN_TREINEIRO', 'CO_UF_ESC', 'TP_DEPENDENCIA_ADM_ESC', 'TP_LOCALIZACAO_ESC', 'CO_UF_PROVA', \n",
    "    'Q001', 'Q002', 'Q003', 'Q004', 'Q005', 'Q006', 'Q007', 'Q008', 'Q009', 'Q010', 'Q011', 'Q012', \n",
    "    'Q013', 'Q014', 'Q015', 'Q016', 'Q017', 'Q018', 'Q019', 'Q020', 'Q021', 'Q022', 'Q023', 'Q024', 'Q025'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise = pd.get_dummies(df, columns=dumies_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_analise.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise.to_parquet('hdfs:///user/jonatas/data/df_tratado_final_dummys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -du -s -h /user/jonatas/data/df_tratado_dummys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primeira análise proposta foi a de selecionar as variávies que mais tem influência para nosso target e somente posteriormente implementar o modelo de previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analise = pd.read_parquet(\"hdfs:///user/jonatas/data/df_tratado_final_dummys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = df_analise.corr()[\"NF_ENEM\"]\n",
    "#lista_abs = df_teste.corr()[\"NF_ENEM\"].abs().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls -h hdfs:///user/jonatas/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_pros = lista.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(lista_pros.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lista_cons = lista.sort_values(ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(lista_cons.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_abs = lista.abs().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(lista_abs[1:126].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = lista_abs.loc[lista_abs >= 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = regressors.index[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_analise[['NF_ENEM'] + regressors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"hdfs:///user/jonatas/data/df_tratado_final_dummys_selected/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!hdfs dfs -ls -h /user/jonatas/data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementação do modelo de previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"hdfs:///user/jonatas/data/df_tratado_final_dummys_selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows = df.shape[0]\n",
    "#rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_teste  = df.sample(np.int(0.02*rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir a Base de teste entre váriáveis dependendes e independente\n",
    "\n",
    "X, y = df.iloc[:,1:].values, df.iloc[:,0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.02, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (X[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "#Definir modelo\n",
    "model = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "#Treinar modelo\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36180393519140785"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testar Modelo\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    ">>> # y = 1 * x_0 + 2 * x_1 + 3\n",
    ">>> y = np.dot(X, np.array([1, 2])) + 3\n",
    ">>> reg = LinearRegression().fit(X, y)\n",
    ">>> reg.score(X, y)\n",
    "1.0\n",
    ">>> reg.coef_\n",
    "array([1., 2.])\n",
    ">>> reg.intercept_\n",
    "3.0...\n",
    ">>> reg.predict(np.array([[3, 5]]))\n",
    "array([16.])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
